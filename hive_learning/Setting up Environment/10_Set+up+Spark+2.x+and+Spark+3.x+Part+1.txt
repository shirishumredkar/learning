### Update PYSPARK_PYTHON at .profile
export PYSPARK_PYTHON=python3
source .profile

### Update /opt/hive/conf/hive-site.xml with below property.
  <property>
    <name>hive.metastore.schema.verification</name>
    <value>false</value>
  </property>

### Spark Website to Download. 
https://downloads.apache.org/spark/

### Download Spark
#3.x
wget https://ftp.wayne.edu/apache/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz

### Untar the File
#3.x
tar xzf spark-3.2.1-bin-hadoop3.2.tgz

### Archive the tar file
#3.x
mv spark-3.2.1-bin-hadoop3.2.tgz softwares

### Set up Spark Folder Structure
#3.x
sudo mv -f spark-3.2.1-bin-hadoop3.2 /opt

### Set up Soft Link
#3.x
sudo ln -s spark-3.2.1-bin-hadoop3.2 /opt/spark3

### spark-env.sh 
#3.x
/opt/spark3/conf/spark-env.sh
export HADOOP_HOME="/opt/hadoop"
export HADOOP_CONF_DIR="/opt/hadoop/etc/hadoop"

#3.x
Update /opt/spark3/conf/spark-defaults.conf with below properties.
spark.driver.extraJavaOptions     -Dderby.system.home=/tmp/derby/
spark.sql.repl.eagerEval.enabled  true
spark.master                      yarn
spark.eventLog.enabled            true
spark.eventLog.dir                hdfs:///spark3-logs
spark.history.provider            org.apache.spark.deploy.history.FsHistoryProvider
spark.history.fs.logDirectory     hdfs:///spark3-logs
spark.history.fs.update.interval  10s
spark.history.ui.port             18080
spark.yarn.historyServer.address  localhost:18080
spark.yarn.jars                   hdfs:///spark3-jars/*.jar

### create directories for logs and jars in HDFS. 
#3.x
hdfs dfs -mkdir /spark3-jars
hdfs dfs -mkdir /spark3-logs


### Copy Spark jars to HDFS folder as part of spark.yarn.jars.
#3.x
hdfs dfs -put /opt/spark3/jars/* /spark3-jars 

### Integrate Spark with Hive Metastore. Create soft link for hive-site.xml in Spark conf folder.
#3.x
sudo ln -s /opt/hive/conf/hive-site.xml /opt/spark3/conf/


### Install  Postgres JDBC jar in Spark jars folder.
#3.x
sudo wget https://jdbc.postgresql.org/download/postgresql-42.2.19.jar \
    -O /opt/spark3/jars/postgresql-42.2.19.jar

### Validate Spark using Scala 
#3.x
/opt/spark3/bin/spark-shell --master yarn --conf spark.ui.port=0

### Validate Spark using Python 
#3.x
/opt/spark3/bin/pyspark --master yarn --conf spark.ui.port=0
spark.sql('SHOW databases').show()
spark.sql('USE test')
spark.sql('SELECT * FROM spark').show() 
exit()

### All the commands(spark-shell,pyspark,spark-submit) are avaiable in:
/opt/spark3/bin

### Set these commands path at .profile. Add below two lines in .profile
#3.x
export PATH=$PATH:/opt/spark3/bin
source .profile

### Distringuish these commands in spark2 and spark3
#3.x
mv /opt/spark3/bin/pyspark /opt/spark3/bin/pyspark3

### Validate the commands
#3.x
pyspark3 --master yarn

############ END ###########

